{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-24T07:58:19.286932Z",
     "start_time": "2025-10-24T07:58:18.400990Z"
    }
   },
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "# --- 1. ì„¤ì • ---\n",
    "# ğŸš¨ [í•„ìˆ˜] 1ë‹¨ê³„ì—ì„œ ë°œê¸‰ë°›ì€ Pixabay API 'Key'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n",
    "API_KEY = \"52913925-73a10d5765a70445e0bd9d899\"  # ì—¬ê¸°ì— Keyë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.\n",
    "# ---------------------\n",
    "\n",
    "# ê²€ìƒ‰ ë° ì €ì¥ ì„¤ì •\n",
    "search_keyword = \"pad thai\", \"íŒŸíƒ€ì´\", \"thai stir fried noodles\", \"à¸œà¸±à¸”à¹„à¸—à¸¢\", \"pad thai noodle\"                 # âœ… ê²€ìƒ‰ì–´ (í•œê¸€, ì˜ì–´ ëª¨ë‘ ê°€ëŠ¥)\n",
    "save_directory = \"./pixabay/pad thai\"  # âœ… ì €ì¥ í´ë”\n",
    "total_images_needed = 400            # âœ… ëª©í‘œ ì´ë¯¸ì§€ ê°œìˆ˜\n",
    "min_size = 256                       # âœ… ìµœì†Œ í”½ì…€ í¬ê¸°\n",
    "\n",
    "# --- 2. ì €ì¥ í´ë” ìƒì„± ---\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "    print(f\"'{save_directory}' í´ë”ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(f\"'{save_directory}' í´ë”ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# --- 3. API í˜¸ì¶œ ë° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ---\n",
    "api_url = \"https://pixabay.com/api/\"\n",
    "\n",
    "image_count = 0  # í˜„ì¬ê¹Œì§€ ë‹¤ìš´ë¡œë“œí•œ (í•„í„°ë§ëœ) ì´ ì´ë¯¸ì§€ ê°œìˆ˜\n",
    "page_num = 1     # API í˜¸ì¶œì„ ì‹œì‘í•  í˜ì´ì§€ ë²ˆí˜¸\n",
    "per_page_count = 100 # í•œ ë²ˆì— 100ê°œì”© ìš”ì²­ (Pixabay ìµœëŒ€ 200)\n",
    "\n",
    "print(f\"'{search_keyword}' í”½ì‚¬ë² ì´ í¬ë¡¤ë§ ì‹œì‘ (ìµœì†Œ {min_size}x{min_size} í¬ê¸°ë§Œ ì €ì¥)\")\n",
    "\n",
    "# ëª©í‘œí•œ 300ê°œë¥¼ ì±„ìš¸ ë•Œê¹Œì§€ ê³„ì† í˜ì´ì§€ë¥¼ ë„˜ê¸°ë©° ê²€ìƒ‰\n",
    "while image_count < total_images_needed:\n",
    "\n",
    "    # Pixabay API íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    params = {\n",
    "        \"key\": \"\",\n",
    "        \"q\": \"pad thai\",\n",
    "        \"image_type\": \"photo\",     # ì‚¬ì§„ë§Œ ê²€ìƒ‰\n",
    "        \"safesearch\": \"true\",      # ì•ˆì „ ê²€ìƒ‰ í™œì„±í™”\n",
    "        \"page\": page_num,\n",
    "        \"per_page\": per_page_count\n",
    "    }\n",
    "\n",
    "    print(f\"--- API í˜¸ì¶œ (page={page_num}) ---\")\n",
    "\n",
    "    try:\n",
    "        # API ìš”ì²­\n",
    "        response = requests.get(api_url, params=params)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        items = data.get(\"hits\", []) # PixabayëŠ” 'hits' í‚¤ì— ê²°ê³¼ê°€ ë“¤ì–´ìˆìŒ\n",
    "        total_hits = data.get(\"totalHits\", 0) # ê²€ìƒ‰ëœ ì´ ì´ë¯¸ì§€ ìˆ˜\n",
    "\n",
    "        if not items:\n",
    "            print(\"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            break\n",
    "\n",
    "        # --- 4. ê°œë³„ ì´ë¯¸ì§€ í•„í„°ë§ ë° ë‹¤ìš´ë¡œë“œ ---\n",
    "        for item in items:\n",
    "            if image_count >= total_images_needed:\n",
    "                break\n",
    "\n",
    "            # PixabayëŠ” ì›ë³¸ í¬ê¸°ë¥¼ 'imageWidth', 'imageHeight'ë¡œ ì œê³µ\n",
    "            img_width = item.get('imageWidth', 0)\n",
    "            img_height = item.get('imageHeight', 0)\n",
    "\n",
    "            # âœ… í•µì‹¬ í•„í„°ë§ ë¡œì§ (min_size = 224ë¡œ ì ìš©ë¨)\n",
    "            if img_width >= min_size and img_height >= min_size:\n",
    "\n",
    "                # âœ¨ 'largeImageURL' (1280px) ë˜ëŠ” 'fullHDURL' (1920px) ì‚¬ìš©\n",
    "                # 'imageURL'ì€ ë„ˆë¬´ í° ì›ë³¸ì¼ ìˆ˜ ìˆìŒ\n",
    "                image_url = item.get('fullHDURL') or item.get('largeImageURL')\n",
    "\n",
    "                if not image_url:\n",
    "                    print(f\"  [SKIP] í¬ê¸°ëŠ” ë§ìœ¼ë‚˜ ({img_width}x{img_height}) ìœ íš¨í•œ URLì´ ì—†ìŒ\")\n",
    "                    continue\n",
    "\n",
    "                image_count += 1\n",
    "\n",
    "                # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ (URLì—ì„œ .jpg, .png ë“±)\n",
    "                file_extension = os.path.splitext(image_url)[1]\n",
    "                if not file_extension: file_extension = \".jpg\" # í™•ì¥ì ì—†ìœ¼ë©´ .jpg\n",
    "\n",
    "                filename = f\"{image_count:04d}{file_extension}\"\n",
    "                filepath = os.path.join(save_directory, filename)\n",
    "\n",
    "                # --- ğŸ’¡ğŸ’¡ğŸ’¡ ìˆ˜ì •ëœ ë¶€ë¶„ (403 Forbidden ì˜¤ë¥˜ í•´ê²°) ğŸ’¡ğŸ’¡ğŸ’¡ ---\n",
    "                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„ (urllib ëŒ€ì‹  requests ì‚¬ìš© ë° User-Agent í—¤ë” ì¶”ê°€)\n",
    "                try:\n",
    "                    # 403 Forbidden ë°©ì§€ë¥¼ ìœ„í•´ ë¸Œë¼ìš°ì € í—¤ë” ì¶”ê°€\n",
    "                    img_headers = {\n",
    "                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "                    }\n",
    "                    img_response = requests.get(image_url, headers=img_headers, stream=True, timeout=10)\n",
    "                    img_response.raise_for_status() # ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ\n",
    "\n",
    "                    # íŒŒì¼ ì“°ê¸° (ìŠ¤íŠ¸ë¦¼ ë°©ì‹)\n",
    "                    with open(filepath, 'wb') as f:\n",
    "                        for chunk in img_response.iter_content(chunk_size=8192):\n",
    "                            f.write(chunk)\n",
    "\n",
    "                    print(f\"  [{image_count}/{total_images_needed}] ì €ì¥ (í¬ê¸°: {img_width}x{img_height}) -> {filepath}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  [ì‹¤íŒ¨] ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {image_url} (ì˜¤ë¥˜: {e})\")\n",
    "                    image_count -= 1\n",
    "                # --- ğŸ’¡ğŸ’¡ğŸ’¡ ìˆ˜ì • ì™„ë£Œ ğŸ’¡ğŸ’¡ğŸ’¡ ---\n",
    "            else:\n",
    "                # 224x224ë³´ë‹¤ ì‘ì•„ì„œ ê±´ë„ˆë›°ëŠ” ê²½ìš°\n",
    "                print(f\"  [SKIP] í¬ê¸°ê°€ ì‘ìŠµë‹ˆë‹¤ ({img_width}x{img_height})\")\n",
    "\n",
    "        # --- 5. ë‹¤ìŒ í˜ì´ì§€ ì¤€ë¹„ ë˜ëŠ” ì¢…ë£Œ ---\n",
    "        total_pages_available = (total_hits + per_page_count - 1) // per_page_count\n",
    "        if page_num >= total_pages_available:\n",
    "            print(\"Pixabayê°€ ì œê³µí•˜ëŠ” ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            break\n",
    "\n",
    "        page_num += 1 # ë‹¤ìŒ í˜ì´ì§€ í˜¸ì¶œ ì¤€ë¹„\n",
    "\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"API ì˜¤ë¥˜ ë°œìƒ: {err}\")\n",
    "        print(\"!!! API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"ìš”ì²­ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nì´ {image_count}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤ (ìµœì†Œ {min_size}x{min_size}).\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./pixabay/pad thai' í´ë”ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\n",
      "'('pad thai', 'íŒŸíƒ€ì´', 'thai stir fried noodles', 'à¸œà¸±à¸”à¹„à¸—à¸¢', 'pad thai noodle')' í”½ì‚¬ë² ì´ í¬ë¡¤ë§ ì‹œì‘ (ìµœì†Œ 256x256 í¬ê¸°ë§Œ ì €ì¥)\n",
      "--- API í˜¸ì¶œ (page=1) ---\n",
      "API ì˜¤ë¥˜ ë°œìƒ: 400 Client Error: Bad Request for url: https://pixabay.com/api/?key=&q=pad+thai&image_type=photo&safesearch=true&page=1&per_page=100\n",
      "!!! API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.\n",
      "\n",
      "ì´ 0ê°œì˜ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤ (ìµœì†Œ 256x256).\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "# --- 1. ì„¤ì • ---\n",
    "# ğŸš¨ [í•„ìˆ˜] 1ë‹¨ê³„ì—ì„œ ë°œê¸‰ë°›ì€ Pixabay API 'Key'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n",
    "API_KEY = \"\"  # ì—¬ê¸°ì— Keyë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.\n",
    "# ---------------------\n",
    "\n",
    "# ê²€ìƒ‰ ë° ì €ì¥ ì„¤ì •\n",
    "search_keyword = \"pad thai\"                 # âœ… ê²€ìƒ‰ì–´ (í•œê¸€, ì˜ì–´ ëª¨ë‘ ê°€ëŠ¥)\n",
    "save_directory = \"./íŒŸíƒ€ì´_í”½ì‚¬ë² ì´_224px\"  # âœ… ì €ì¥ í´ë”\n",
    "total_images_needed = 300            # âœ… ëª©í‘œ ì´ë¯¸ì§€ ê°œìˆ˜\n",
    "min_size = 224                       # âœ… ìµœì†Œ í”½ì…€ í¬ê¸°\n",
    "\n",
    "# --- 2. ì €ì¥ í´ë” ìƒì„± ---\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "    print(f\"'{save_directory}' í´ë”ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(f\"'{save_directory}' í´ë”ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# --- 3. API í˜¸ì¶œ ë° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ---\n",
    "api_url = \"https://pixabay.com/api/\"\n",
    "\n",
    "image_count = 0  # í˜„ì¬ê¹Œì§€ ë‹¤ìš´ë¡œë“œí•œ (í•„í„°ë§ëœ) ì´ ì´ë¯¸ì§€ ê°œìˆ˜\n",
    "page_num = 1     # API í˜¸ì¶œì„ ì‹œì‘í•  í˜ì´ì§€ ë²ˆí˜¸\n",
    "per_page_count = 100 # í•œ ë²ˆì— 100ê°œì”© ìš”ì²­ (Pixabay ìµœëŒ€ 200)\n",
    "\n",
    "print(f\"'{search_keyword}' í”½ì‚¬ë² ì´ í¬ë¡¤ë§ ì‹œì‘ (ìµœì†Œ {min_size}x{min_size} í¬ê¸°ë§Œ ì €ì¥)\")\n",
    "\n",
    "# ëª©í‘œí•œ 300ê°œë¥¼ ì±„ìš¸ ë•Œê¹Œì§€ ê³„ì† í˜ì´ì§€ë¥¼ ë„˜ê¸°ë©° ê²€ìƒ‰\n",
    "while image_count < total_images_needed:\n",
    "\n",
    "    # Pixabay API íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "    params = {\n",
    "        \"key\": \"\",\n",
    "        \"q\": \"pad thai\",\n",
    "        \"image_type\": \"photo\",     # ì‚¬ì§„ë§Œ ê²€ìƒ‰\n",
    "        \"safesearch\": \"true\",      # ì•ˆì „ ê²€ìƒ‰ í™œì„±í™”\n",
    "        \"page\": page_num,\n",
    "        \"per_page\": per_page_count\n",
    "    }\n",
    "\n",
    "    print(f\"--- API í˜¸ì¶œ (page={page_num}) ---\")\n",
    "\n",
    "    try:\n",
    "        # API ìš”ì²­\n",
    "        response = requests.get(api_url, params=params)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        items = data.get(\"hits\", []) # PixabayëŠ” 'hits' í‚¤ì— ê²°ê³¼ê°€ ë“¤ì–´ìˆìŒ\n",
    "        total_hits = data.get(\"totalHits\", 0) # ê²€ìƒ‰ëœ ì´ ì´ë¯¸ì§€ ìˆ˜\n",
    "\n",
    "        if not items:\n",
    "            print(\"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            break\n",
    "\n",
    "        # --- 4. ê°œë³„ ì´ë¯¸ì§€ í•„í„°ë§ ë° ë‹¤ìš´ë¡œë“œ ---\n",
    "        for item in items:\n",
    "            if image_count >= total_images_needed:\n",
    "                break\n",
    "\n",
    "            # PixabayëŠ” ì›ë³¸ í¬ê¸°ë¥¼ 'imageWidth', 'imageHeight'ë¡œ ì œê³µ\n",
    "            img_width = item.get('imageWidth', 0)\n",
    "            img_height = item.get('imageHeight', 0)\n",
    "\n",
    "            # âœ… í•µì‹¬ í•„í„°ë§ ë¡œì§ (min_size = 224ë¡œ ì ìš©ë¨)\n",
    "            if img_width >= min_size and img_height >= min_size:\n",
    "\n",
    "                # âœ¨ 'largeImageURL' (1280px) ë˜ëŠ” 'fullHDURL' (1920px) ì‚¬ìš©\n",
    "                # 'imageURL'ì€ ë„ˆë¬´ í° ì›ë³¸ì¼ ìˆ˜ ìˆìŒ\n",
    "                image_url = item.get('fullHDURL') or item.get('largeImageURL')\n",
    "\n",
    "                if not image_url:\n",
    "                    print(f\"  [SKIP] í¬ê¸°ëŠ” ë§ìœ¼ë‚˜ ({img_width}x{img_height}) ìœ íš¨í•œ URLì´ ì—†ìŒ\")\n",
    "                    continue\n",
    "\n",
    "                image_count += 1\n",
    "\n",
    "                # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ (URLì—ì„œ .jpg, .png ë“±)\n",
    "                file_extension = os.path.splitext(image_url)[1]\n",
    "                if not file_extension: file_extension = \".jpg\" # í™•ì¥ì ì—†ìœ¼ë©´ .jpg\n",
    "\n",
    "                filename = f\"{image_count:04d}{file_extension}\"\n",
    "                filepath = os.path.join(save_directory, filename)\n",
    "\n",
    "                # --- ğŸ’¡ğŸ’¡ğŸ’¡ ìˆ˜ì •ëœ ë¶€ë¶„ (403 Forbidden ì˜¤ë¥˜ í•´ê²°) ğŸ’¡ğŸ’¡ğŸ’¡ ---\n",
    "                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„ (urllib ëŒ€ì‹  requests ì‚¬ìš© ë° User-Agent í—¤ë” ì¶”ê°€)\n",
    "                try:\n",
    "                    # 403 Forbidden ë°©ì§€ë¥¼ ìœ„í•´ ë¸Œë¼ìš°ì € í—¤ë” ì¶”ê°€\n",
    "                    img_headers = {\n",
    "                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "                    }\n",
    "                    img_response = requests.get(image_url, headers=img_headers, stream=True, timeout=10)\n",
    "                    img_response.raise_for_status() # ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ\n",
    "\n",
    "                    # íŒŒì¼ ì“°ê¸° (ìŠ¤íŠ¸ë¦¼ ë°©ì‹)\n",
    "                    with open(filepath, 'wb') as f:\n",
    "                        for chunk in img_response.iter_content(chunk_size=8192):\n",
    "                            f.write(chunk)\n",
    "\n",
    "                    print(f\"  [{image_count}/{total_images_needed}] ì €ì¥ (í¬ê¸°: {img_width}x{img_height}) -> {filepath}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  [ì‹¤íŒ¨] ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {image_url} (ì˜¤ë¥˜: {e})\")\n",
    "                    image_count -= 1\n",
    "                # --- ğŸ’¡ğŸ’¡ğŸ’¡ ìˆ˜ì • ì™„ë£Œ ğŸ’¡ğŸ’¡ğŸ’¡ ---\n",
    "            else:\n",
    "                # 224x224ë³´ë‹¤ ì‘ì•„ì„œ ê±´ë„ˆë›°ëŠ” ê²½ìš°\n",
    "                print(f\"  [SKIP] í¬ê¸°ê°€ ì‘ìŠµë‹ˆë‹¤ ({img_width}x{img_height})\")\n",
    "\n",
    "        # --- 5. ë‹¤ìŒ í˜ì´ì§€ ì¤€ë¹„ ë˜ëŠ” ì¢…ë£Œ ---\n",
    "        total_pages_available = (total_hits + per_page_count - 1) // per_page_count\n",
    "        if page_num >= total_pages_available:\n",
    "            print(\"Pixabayê°€ ì œê³µí•˜ëŠ” ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            break\n",
    "\n",
    "        page_num += 1 # ë‹¤ìŒ í˜ì´ì§€ í˜¸ì¶œ ì¤€ë¹„\n",
    "\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"API ì˜¤ë¥˜ ë°œìƒ: {err}\")\n",
    "        print(\"!!! API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"ìš”ì²­ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nì´ {image_count}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤ (ìµœì†Œ {min_size}x{min_size}).\")\n",
    "\n"
   ],
   "id": "39f8b0e800171661"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
